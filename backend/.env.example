# LLM Provider Configuration
# 选择主要的LLM提供商: gemini, azure_openai, aws_bedrock, openai_compatible
LLM_PROVIDER=gemini

# Google Gemini Configuration
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODELS=gemini-2.0-flash,gemini-2.5-flash,gemini-2.5-pro
GEMINI_DEFAULT_MODEL=gemini-2.5-flash
GEMINI_TIMEOUT=30.0
GEMINI_MAX_RETRIES=3

# Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_MODELS=gpt-4,gpt-4-turbo,gpt-35-turbo,gpt-4o
AZURE_OPENAI_DEFAULT_MODEL=gpt-4
AZURE_OPENAI_TIMEOUT=30.0
AZURE_OPENAI_MAX_RETRIES=3

# AWS Bedrock Configuration
AWS_ACCESS_KEY_ID=your_aws_access_key_id_here
AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key_here
AWS_REGION=us-east-1
BEDROCK_MODELS=anthropic.claude-3-sonnet-20240229-v1:0,anthropic.claude-3-haiku-20240307-v1:0,anthropic.claude-3-opus-20240229-v1:0
BEDROCK_DEFAULT_MODEL=anthropic.claude-3-sonnet-20240229-v1:0
BEDROCK_TIMEOUT=30.0
BEDROCK_MAX_RETRIES=3

# OpenAI Compatible Configuration (for Ollama, vLLM, LocalAI, etc.)
OPENAI_COMPATIBLE_API_KEY=your_api_key_here_or_dummy_for_local
OPENAI_COMPATIBLE_BASE_URL=http://localhost:11434/v1
OPENAI_COMPATIBLE_MODELS=llama2,codellama,mistral
OPENAI_COMPATIBLE_DEFAULT_MODEL=llama2
OPENAI_COMPATIBLE_TIMEOUT=30.0
OPENAI_COMPATIBLE_MAX_RETRIES=3

# Search Provider Configuration
SEARCH_PROVIDER=google
SEARCH_RESULTS_LIMIT=10

# Google Search (via Gemini)
# Uses GEMINI_API_KEY from above

# Tavily Search
TAVILY_API_KEY=your_tavily_api_key_here
TAVILY_BASE_URL=https://api.tavily.com
TAVILY_TIMEOUT=30.0

# Agent Configuration
NUMBER_OF_INITIAL_QUERIES=3
MAX_RESEARCH_LOOPS=2
TEMPERATURE=0.7
MAX_TOKENS=
REQUEST_TIMEOUT=30.0
MAX_RETRIES=3

# Model Assignment for Different Tasks
# 可以为不同任务指定不同的模型
QUERY_GENERATOR_MODEL=gemini-2.0-flash
REFLECTION_MODEL=gemini-2.5-flash
ANSWER_MODEL=gemini-2.5-pro

# Development Configuration
DEBUG=false
LOG_LEVEL=INFO

# LangSmith Configuration (Optional)
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGSMITH_PROJECT=gemini-fullstack-langgraph