import os
import time
import asyncio
from typing import List, Dict, Any, Optional
from google.genai import Client

from agent.search_providers import (
    BaseSearchProvider,
    SearchRequest,
    SearchResult,
    SearchMetrics,
    SearchProviderAPIError,
    SearchProviderTimeoutError,
    SearchProviderRateLimitError
)



class GoogleSearchProvider(BaseSearchProvider):
    """Googleæœç´¢æä¾›å•†å®ç°
    
    ä½¿ç”¨Googleçš„GenAIå®¢æˆ·ç«¯æä¾›çš„æœç´¢åŠŸèƒ½æ¥æ‰§è¡Œç½‘ç»œæœç´¢ã€‚
    """
    
    def __init__(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–Googleæœç´¢æä¾›å•†
        
        Args:
            config: é…ç½®å­—å…¸ï¼Œéœ€è¦åŒ…å« 'api_key' å­—æ®µ
        """
        super().__init__(config)
        self.client = Client(api_key=config["api_key"])
        self.model = config.get("model", "gemini-2.0-flash")
        self._last_metrics: Optional[SearchMetrics] = None
    
    async def search(self, request: SearchRequest) -> SearchResult:
        """æ‰§è¡ŒGoogleæœç´¢
        
        Args:
            request: æœç´¢è¯·æ±‚å¯¹è±¡
            
        Returns:
            SearchResult: æ ‡å‡†åŒ–çš„æœç´¢ç»“æœ
        """
        start_time = time.time()
        
        try:
            # æ„å»ºæœç´¢æç¤º
            search_prompt = self._build_search_prompt(request)
            
            # æ‰§è¡Œæœç´¢ (ä½¿ç”¨å¼‚æ­¥åŒ…è£…åŒæ­¥è°ƒç”¨)
            response = await asyncio.to_thread(
                self.client.models.generate_content,
                model=self.model,
                contents=search_prompt,
                config={
                    "tools": [{"google_search": {}}],
                    "temperature": 0,
                }
            )
            
            # å¤„ç†æœç´¢ç»“æœ (ä½¿ç”¨å¼‚æ­¥åŒ…è£…)
            search_result = await asyncio.to_thread(self._process_response, response, request)
            
            # è®°å½•æ€§èƒ½æŒ‡æ ‡
            end_time = time.time()
            self._last_metrics = SearchMetrics(
                search_time=end_time - start_time,
                result_count=len(search_result.sources),
                api_calls_used=1,
                tokens_consumed=getattr(response, 'token_count', None)
            )
            
            return search_result
            
        except Exception as e:
            # æ ¹æ®é”™è¯¯ç±»å‹æŠ›å‡ºç›¸åº”çš„å¼‚å¸¸
            if "timeout" in str(e).lower():
                raise SearchProviderTimeoutError(f"Googleæœç´¢è¶…æ—¶: {e}")
            elif "rate limit" in str(e).lower() or "quota" in str(e).lower():
                raise SearchProviderRateLimitError(f"Googleæœç´¢é€Ÿç‡é™åˆ¶: {e}")
            else:
                raise SearchProviderAPIError(f"Googleæœç´¢APIé”™è¯¯: {e}")
    
    def _build_search_prompt(self, request: SearchRequest) -> str:
        """æ„å»ºæœç´¢æç¤º
        
        Args:
            request: æœç´¢è¯·æ±‚
            
        Returns:
            str: æ„å»ºçš„æœç´¢æç¤º
        """
        prompt = f"""
è¯·åŸºäºä»¥ä¸‹æŸ¥è¯¢è¿›è¡Œç½‘ç»œæœç´¢ï¼Œå¹¶æä¾›è¯¦ç»†çš„ä¿¡æ¯æ€»ç»“ï¼š

æŸ¥è¯¢: {request.query}

è¦æ±‚:
- æœç´¢ç›¸å…³çš„æœ€æ–°ä¿¡æ¯
- æä¾›è¯¦ç»†çš„å†…å®¹æ€»ç»“
- åŒ…å«å¯é çš„æ¥æºé“¾æ¥
- æœ€å¤šè¿”å› {request.max_results} ä¸ªç›¸å…³ç»“æœ
        """
        
        if request.language:
            prompt += f"\n- ä¼˜å…ˆæœç´¢ {request.language} è¯­è¨€çš„å†…å®¹"
            
        if request.date_restrict:
            prompt += f"\n- æ—¶é—´èŒƒå›´é™åˆ¶: {request.date_restrict}"
            
        return prompt.strip()
    
    def _clean_fake_citations(self, text: str) -> str:
        """æ¸…ç†Gemini APIè‡ªåŠ¨ç”Ÿæˆçš„å‡å¼•ç”¨é“¾æ¥
        
        Args:
            text: åŒ…å«å‡é“¾æ¥çš„åŸå§‹æ–‡æœ¬
            
        Returns:
            str: æ¸…ç†åçš„æ–‡æœ¬
        """
        import re
        
        # ç§»é™¤æ‰€æœ‰å½¢å¦‚ [label](https://vertexaisearch.cloud.google.com/...) çš„å‡é“¾æ¥
        # ä½†ä¿ç•™labelæ–‡æœ¬
        pattern = r'\[([^\]]+)\]\(https://vertexaisearch\.cloud\.google\.com/[^)]+\)'
        cleaned_text = re.sub(pattern, r'\1', text)
        
        # ç§»é™¤å•ç‹¬çš„vertexaisearché“¾æ¥ï¼ˆæ²¡æœ‰labelçš„æƒ…å†µï¼‰
        pattern2 = r'https://vertexaisearch\.cloud\.google\.com/[^\s\])]+'
        cleaned_text = re.sub(pattern2, '', cleaned_text)
        
        return cleaned_text.strip()
    
    def _process_response(self, response, request: SearchRequest) -> SearchResult:
        """å¤„ç†Googleæœç´¢å“åº”
        
        Args:
            response: Google GenAIå“åº”å¯¹è±¡
            request: åŸå§‹æœç´¢è¯·æ±‚
            
        Returns:
            SearchResult: æ ‡å‡†åŒ–çš„æœç´¢ç»“æœ
        """
        try:
            # ç›´æ¥ä»grounding chunksè·å–çœŸå®URLï¼Œä¸ä½¿ç”¨resolve_urlsè½¬æ¢
            grounding_chunks = response.candidates[0].grounding_metadata.grounding_chunks
            
            # æ„å»ºæ¥æºåˆ—è¡¨ - ç›´æ¥ä½¿ç”¨çœŸå®URL
            sources = []
            seen_urls = set()
            
            for i, chunk in enumerate(grounding_chunks):
                if hasattr(chunk, 'web') and hasattr(chunk.web, 'uri'):
                    real_url = chunk.web.uri  # ä¿ç•™åŸå§‹çš„vertexaisearché“¾æ¥ï¼Œè¿™äº›ä¼šé‡å®šå‘åˆ°çœŸå®ç½‘ç«™
                    title = getattr(chunk.web, 'title', f"æœç´¢ç»“æœ{i+1}")
                    
                    print(f"ğŸ” å¤„ç†grounding chunk {i+1}: [{title}] -> {real_url[:50]}...")
                    
                    # é¿å…é‡å¤URL
                    if real_url not in seen_urls:
                        sources.append({
                            "label": f"æ¥æº{i+1}",
                            "url": real_url,  # ä½¿ç”¨åŸå§‹URLï¼ˆGoogleçš„é‡å®šå‘é“¾æ¥ï¼‰
                            "title": title
                        })
                        seen_urls.add(real_url)
                    else:
                        print(f"â­ï¸ è·³è¿‡é‡å¤URL")
            
            # é™åˆ¶ç»“æœæ•°é‡
            sources = sources[:request.max_results]
            
            # æ¸…ç†Gemini APIè‡ªåŠ¨ç”Ÿæˆçš„å‡é“¾æ¥
            clean_content = self._clean_fake_citations(response.text)
            
            return SearchResult(
                content=clean_content,
                sources=sources,
                metadata={
                    "provider": "google",
                    "model": self.model,
                    "query": request.query,
                    "original_response_text": response.text,
                    "total_sources_found": len(sources)
                }
            )
            
        except Exception as e:
            # å¦‚æœå¤„ç†å¤±è´¥ï¼Œè¿”å›åŸºç¡€ç»“æœ
            return SearchResult(
                content=response.text if hasattr(response, 'text') else "æœç´¢å¤±è´¥",
                sources=[],
                metadata={
                    "provider": "google",
                    "model": self.model,
                    "query": request.query,
                    "error": str(e)
                }
            )
    
    def get_provider_name(self) -> str:
        """è¿”å›æä¾›å•†åç§°"""
        return "google"
    
    def validate_config(self) -> bool:
        """éªŒè¯é…ç½®æ˜¯å¦æœ‰æ•ˆ"""
        try:
            api_key = self.config.get("api_key")
            if not api_key:
                return False
                
            # éªŒè¯APIå¯†é’¥æ ¼å¼ï¼ˆåŸºæœ¬æ£€æŸ¥ï¼‰
            if not isinstance(api_key, str) or len(api_key) < 10:
                return False
                
            return True
        except Exception:
            return False
    
    def get_required_config_keys(self) -> List[str]:
        """è·å–å¿…éœ€çš„é…ç½®é”®åˆ—è¡¨"""
        return ["api_key"]
    
    def get_rate_limits(self) -> Dict[str, Any]:
        """è·å–APIé€Ÿç‡é™åˆ¶ä¿¡æ¯"""
        return {
            "requests_per_minute": 60,  # Google GenAIçš„å…¸å‹é™åˆ¶
            "requests_per_day": 1500,
            "concurrent_requests": 5,
            "notes": "å®é™…é™åˆ¶å¯èƒ½å› APIè®¡åˆ’è€Œå¼‚"
        }
    
    def get_supported_features(self) -> List[str]:
        """è·å–æ”¯æŒçš„æœç´¢åŠŸèƒ½"""
        return [
            "web_search",
            "real_time_results",
            "grounding_metadata",
            "citation_support",
            "multi_language",
            "safe_search"
        ] 